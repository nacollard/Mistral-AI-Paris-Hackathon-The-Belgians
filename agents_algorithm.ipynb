{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 134,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from mistralai.client import MistralClient\n",
            "from mistralai.models.chat_completion import ChatMessage\n",
            "from dotenv import load_dotenv\n",
            "from docx import Document\n",
            "import xml.etree.ElementTree as ET\n",
            "from OpenRAG.src.openrag.chunk_vectorization.chunk_vectorization import get_vectorizer\n",
            "from OpenRAG.src.openrag.vectordb.milvus_adapter import init_milvus_connection\n",
            "from pymilvus import Collection\n",
            "import os\n",
            "import json\n",
            "import re\n",
            "import xml.etree.ElementTree as ET\n",
            "\n",
            "load_dotenv()  # take environment variables from .env.\n",
            "def xml_retriever(xml_response, tag, default=None):\n",
            "    \"\"\"\n",
            "    Retrieve the content between the specified XML tags.\n",
            "\n",
            "    Args:\n",
            "        xml_response (str): The XML response.\n",
            "        tag (str): The XML tag to retrieve the content from.\n",
            "        default (optional): The value to return if the tag is not found.\n",
            "\n",
            "    Returns:\n",
            "        str or default: The content between the specified XML tags or the default value.\n",
            "    \"\"\"\n",
            "    try:\n",
            "        start_tag = f\"<{tag}>\"\n",
            "        end_tag = f\"</{tag}>\"\n",
            "        start_index = xml_response.index(start_tag) + len(start_tag)\n",
            "        end_index = xml_response.index(end_tag, start_index)\n",
            "        return xml_response[start_index:end_index]\n",
            "    except ValueError:\n",
            "        return default\n",
            "\n",
            "\n",
            "def send_request_to_mistral_ai(model, messages):\n",
            "    \"\"\"\n",
            "    Send a request to the Mistral AI model and return the response.\n",
            "\n",
            "    Args:\n",
            "        model (str): The Mistral AI model to use.\n",
            "        messages (List[ChatMessage]): The messages to send in the request.\n",
            "\n",
            "    Returns:\n",
            "        str: The response from the Mistral AI model.\n",
            "    \"\"\"\n",
            "    api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
            "    if not api_key:\n",
            "        raise ValueError(\"MISTRAL_API_KEY not found in environment variables.\")\n",
            "    client = MistralClient(api_key=api_key)\n",
            "\n",
            "    try:\n",
            "        chat_response = client.chat(\n",
            "            model=model,\n",
            "            messages=messages,\n",
            "        )\n",
            "\n",
            "        response = chat_response.choices[0].message.content\n",
            "        return response\n",
            "    except Exception as e:\n",
            "        print(f\"Error in Mistral AI request: {e}\")\n",
            "        return None\n",
            "\n",
            "\n",
            "def load_company_knowledge():\n",
            "    \"\"\"\n",
            "    Load company knowledge from company documents.\n",
            "\n",
            "    Returns:\n",
            "        str: The combined text from all company documents.\n",
            "    \"\"\"\n",
            "    business_model = \"Data/Internal/Business Model de StIT.docx\"\n",
            "    long_term_strategy = (\n",
            "        \"Data/Internal/Plan de développement stratégique sur 8 ans pour StIT.docx\"\n",
            "    )\n",
            "    products_and_services = \"Data/Internal/Produits et services de StIT.docx\"\n",
            "    company_docs = [business_model, long_term_strategy, products_and_services]\n",
            "    company_knowledge = \"\"\n",
            "\n",
            "    for doc in company_docs:\n",
            "        docx_document = Document(doc)\n",
            "        paragraphs_text = \" \".join(\n",
            "            [paragraph.text for paragraph in docx_document.paragraphs]\n",
            "        )\n",
            "        company_knowledge += paragraphs_text\n",
            "\n",
            "    return company_knowledge\n",
            "\n",
            "\n",
            "def find_chunks(id, path=\"Data/Internal/HR/\"):\n",
            "    \"\"\"\n",
            "    Find the chunk based on the given id.\n",
            "\n",
            "    Args:\n",
            "        id (int): The id of the chunk to find.\n",
            "        path (str, optional): The path to the chunk files. Defaults to \"Data/Internal/HR/\".\n",
            "\n",
            "    Returns:\n",
            "        dict: A dictionary containing the chunk details, or None if the chunk is not found.\n",
            "    \"\"\"\n",
            "    global_indexing = json.load(open(\"global_indexing.json\", \"r\"))\n",
            "    for key, value in global_indexing.items():\n",
            "        start_idx = value[\"start\"]\n",
            "        end_idx = value[\"end\"]\n",
            "        if start_idx <= id <= end_idx:\n",
            "            index_in_file = id - start_idx\n",
            "            data_dict_file = json.load(open(path + key + \"_chunks.json\", \"r\"))\n",
            "            data_dict_file[\"chunk_\" + str(index_in_file)][\"document\"] = key + \".docx\"\n",
            "            data_dict_file[\"chunk_\" + str(index_in_file)][\"fullpath\"] = (\n",
            "                path + key + \".docx\"\n",
            "            )\n",
            "            return data_dict_file[\"chunk_\" + str(index_in_file)]\n",
            "    return None\n",
            "def create_prompt_analyst_agent(context, company_knowledge, type):\n",
            "    \"\"\"\n",
            "    Create the prompt for the Mistral AI model.\n",
            "\n",
            "    Args:\n",
            "        article (str): The news article to analyze.\n",
            "        company_knowledge (str): The company knowledge to include in the prompt.\n",
            "\n",
            "    Returns:\n",
            "        str: The prompt for the Mistral AI model.\n",
            "    \"\"\"\n",
            "    prompt = f\"\"\"\n",
            "                You are an experienced business analyst tasked with determining the priority level of {type}s based on their relevance to your company, StIT.\n",
            "\n",
            "                Here is some crucial information about the company to consider during your analysis:\n",
            "                <company_knowledge>{company_knowledge}</company_knowledge>\n",
            "\n",
            "                Please thoroughly read and analyze the following {type}:\n",
            "\n",
            "                <{type}>{context}</{type}>\n",
            "\n",
            "                After completing your analysis, provide your final assessment in the <output> section, using the following format:\n",
            "\n",
            "                <output>\n",
            "                <priority_level>High OR Medium OR Low</priority_level>\n",
            "                <justification>A detailed explanation of your priority rating, including how the {type}'s main points and key details relate to the company's goals, operations, or industry, and the potential implications and impact of the {type} on the company</justification>\n",
            "                <main_topic>A one-sentence summary highlighting the {type}'s main topic<main_topic>\n",
            "                </output>\n",
            "\n",
            "                Remember, your goal is to help company management quickly identify and prioritize important {type}s, so be sure to consider the key implications and potential impact of the {type} on the company in your priority rating and justification.\n",
            "            \"\"\"\n",
            "    return prompt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 137,
         "metadata": {},
         "outputs": [],
         "source": [
            "def create_prompt_strategy_agent(context, stretegic_info):\n",
            "    prompt = f\"\"\"\n",
            "                You are an experienced strategic consultant. \n",
            "                I will provide you with some context about a situation and the employee you have to advice. I'll also provide you strategic information about the company. \n",
            "                Your task is to build a quick action plan for the employee the message is addressed to, on how they can best tackle the matter to help the company based on their experience and position in the company. \n",
            "\n",
            "                Here is the context with the employee you have to advice and information about the situation:\n",
            "                <context>{context}</context>\n",
            "\n",
            "                Here is the strategic information about the company:\n",
            "                <strategic_info>{stretegic_info}</strategic_info>\n",
            "\n",
            "                First, take a moment to carefully read and understand the context, strategic information, and who is the employee you advice. Think through the key considerations and how the employee can best respond given the company's strategic priorities and his or her position. Write your thoughts in a <scratchpad> section.\n",
            "\n",
            "                Then, provide a short action plan with a few concrete steps the employee can follow to effectively address this situation in a way that aligns with and supports the company's strategy. Write the action plan inside <action_plan> tags.\n",
            "\n",
            "                The action plan should be concise and to-the-point, focusing on the most critical steps the employee should take. Aim for 3-5 key action items.\n",
            "\n",
            "                Remember, your goal is to guide the employee on how to tackle this matter in a way that will best help the company achieve its strategic objectives, based on your understanding of the context, company strategy, and the specific situation described in the message.\n",
            "                \"\"\"\n",
            "    return prompt\n",
            "\n",
            "\n",
            "def strategy_agent(context, employee):\n",
            "    strategic_info = load_company_knowledge()\n",
            "    cv_path = Document(f\"Data/Internal/HR/CV {employee}.docx\")\n",
            "    employee_CV = \" \".join([paragraph.text for paragraph in cv_path.paragraphs])\n",
            "    strategic_info += employee_CV\n",
            "    prompt = create_prompt_strategy_agent(context, strategic_info)\n",
            "    messages = [\n",
            "        ChatMessage(role=\"system\", content=prompt),\n",
            "        ChatMessage(role=\"user\", content=\"The matter : \" + context),\n",
            "    ]\n",
            "\n",
            "    model = \"mistral-large-latest\"\n",
            "\n",
            "    response = send_request_to_mistral_ai(model, messages)\n",
            "    print(\"Strategic advisor response: \", response)\n",
            "    return response"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def analyst_agent(context, type):\n",
            "    \"\"\"\n",
            "    Analyze the given news article and dispatch it to the appropriate agent.\n",
            "\n",
            "    Args:\n",
            "        article (str): The news article to analyze.\n",
            "\n",
            "    Returns:\n",
            "        None\n",
            "    \"\"\"\n",
            "    docx_document = Document(context)\n",
            "    context_content = \" \".join(\n",
            "        [paragraph.text for paragraph in docx_document.paragraphs]\n",
            "    )\n",
            "\n",
            "    company_knowledge = load_company_knowledge()\n",
            "\n",
            "    prompt = create_prompt_analyst_agent(context_content, company_knowledge, type)\n",
            "\n",
            "    model = \"mistral-large-latest\"\n",
            "\n",
            "    messages = [\n",
            "        ChatMessage(role=\"system\", content=prompt),\n",
            "        ChatMessage(\n",
            "            role=\"user\", content=f\"Content of the {type}  : \" + context_content\n",
            "        ),\n",
            "    ]\n",
            "\n",
            "    xml_response = send_request_to_mistral_ai(model, messages)\n",
            "\n",
            "    priority_level = xml_retriever(xml_response, \"priority_level\")\n",
            "    justification = xml_retriever(xml_response, \"justification\")\n",
            "    main_topic = xml_retriever(xml_response, \"main_topic\")\n",
            "\n",
            "    print(\"Priority Level: \", priority_level)\n",
            "    print(\"Justification: \", justification)\n",
            "    print(\"Main Topic: \", main_topic)\n",
            "\n",
            "    employees_to_inform = dispatch_agent(main_topic, justification)\n",
            "    if priority_level == \"High\":\n",
            "        # print(\"High priority level detected.\")\n",
            "        employee = employees_to_inform[0]\n",
            "        print(f\"/!\\ Informing {employee} about the high priority {type}. /!\\ \")\n",
            "        context_to_pass = f\"<employee_name>employee</employee_name>, <priority_level>High</priority_level>, <main_topic>{main_topic}</main_topic>, <justification>{justification}</justification>, <context>{context}</context>, <type>{type}</type>\"\n",
            "        strategy_agent(context_to_pass, employee)\n",
            "    return employees_to_inform, priority_level, main_topic, context, justification, type\n",
            "def create_prompt_dispatch_agent(main_topic, justification, CVs):\n",
            "    \"\"\"\n",
            "    Create the prompt for the Mistral AI model.\n",
            "\n",
            "    Args:\n",
            "        maint_topic (str): The main topic of the news article to analyze.\n",
            "        justification (str): The reason why the news article might be relevant to the company.\n",
            "        CVs (str): The CVs of the employees.\n",
            "\n",
            "    Returns:\n",
            "        str: The prompt for the Mistral AI model.\n",
            "    \"\"\"\n",
            "\n",
            "    prompt = f\"\"\"\n",
            "                You are a senior executive at StIT, and you have been tasked with identifying the employees who should be informed about a specific matter based on their expertise and role within the company.\n",
            "                Please thoroughly read and analyze the following matter:\n",
            "\n",
            "                <matter>{main_topic} {justification}</matter>\n",
            "                Now read carefully the CVs of the following employees and rank them in order of relevance to the matter:\n",
            "                <CVs>{CVs}</CVs>\n",
            "                In the <output> section, write down the names of the employees who are relevant to contact for this matter. Carefully consider how the main points and key details of this matter relate to the provided CVs and job titles at StIT to select the relevant employees.\n",
            "\n",
            "                After completing your analysis, provide your final assessment in the <output> section, using the following format:\n",
            "\n",
            "                <output>\n",
            "                <total>NUMBER</total> \n",
            "                <employee1>NAME_EMPLOYEE1</employee1> \n",
            "                <employee2>NAME_EMPLOYEE2</employee2>\n",
            "                <employee3>NAME_EMPLOYEE3</employee3>\n",
            "                <employee4>NAME_EMPLOYEE4</employee4>\n",
            "                <employee5>NAME_EMPLOYEE5</employee5>\n",
            "                </output>\n",
            "                In the <total> tag, write down the number of employees that you judge enough to be informed about the matter. In the <employeeN> tags, write down the names of the employees that you have selected, in order of relevance. If no employee is relevant, please write \"None\" in the <total> tag.\n",
            "\n",
            "                Remember, your goal is to help company management quickly identify and prioritize the employees to inform about the matter, so be sure to consider the key implications and potential impact of the matter on the company in your selection of relevant profiles to inform about it. Also, keep in mind that the employees receive push notifications, so it doesn't make sense to inform too many of them if not relevant for all of them to get informed.\n",
            "                \"\"\"\n",
            "    return prompt\n",
            "\n",
            "\n",
            "def dispatch_agent(main_topic, justification):\n",
            "    \"\"\"\n",
            "    Determine the employee(s) who should be informed about the given topic and justification.\n",
            "\n",
            "    Args:\n",
            "        main_topic (str): The main topic of the news.\n",
            "        justification (str): The justification for the priority level of the news.\n",
            "\n",
            "    Returns:\n",
            "        None\n",
            "    \"\"\"\n",
            "    results = internal_retriever_agent(main_topic)\n",
            "\n",
            "    CVs = []\n",
            "    for result in results:\n",
            "        content_cv = \"\"\n",
            "        docx_document = Document(result[\"fullpath\"])\n",
            "        paragraphs_text = \" \".join(\n",
            "            [paragraph.text for paragraph in docx_document.paragraphs]\n",
            "        )\n",
            "        content_cv += paragraphs_text\n",
            "        # The input string\n",
            "        filename = result[\"fullpath\"]\n",
            "\n",
            "        # The regular expression pattern to match the name\n",
            "        pattern = r\"/CV\\s*(.+?)\\.docx\"\n",
            "\n",
            "        # Search for the pattern in the input string\n",
            "        match = re.search(pattern, filename)\n",
            "        name = match.group(1)\n",
            "        # The name is in between 'CV' and '.docx'\n",
            "        CVs.append(\"Name: \" + name + \" \" + content_cv)\n",
            "\n",
            "    prompt = create_prompt_dispatch_agent(main_topic, justification, CVs)\n",
            "    messages = [\n",
            "        ChatMessage(role=\"system\", content=prompt),\n",
            "        ChatMessage(role=\"user\", content=\"The matter : \" + main_topic + justification),\n",
            "    ]\n",
            "\n",
            "    model = \"mistral-large-latest\"\n",
            "\n",
            "    employees_to_inform = send_request_to_mistral_ai(model, messages)\n",
            "    pattern = r\"<output>.*</output>\"\n",
            "    print(\"Employees to inform: \", employees_to_inform)\n",
            "    try:\n",
            "        # Search for the pattern in the string and extract the match\n",
            "        match = re.search(pattern, employees_to_inform, re.DOTALL)\n",
            "        xml_content = match.group(0) if match else None\n",
            "        # Parse the XML string into an ElementTree object\n",
            "        root = ET.fromstring(xml_content.strip())\n",
            "    except re.error as e:\n",
            "        # Handle the exceptions raised by the re module\n",
            "        print(employees_to_inform)\n",
            "        print(f\"An error occurred while processing the regular expression: {e}\")\n",
            "    except ET.ParseError as e:\n",
            "        # Handle the exceptions raised by the ET module\n",
            "        print(xml_content)\n",
            "        print(f\"An error occurred while parsing the XML string: {e}\")\n",
            "    except Exception as e:\n",
            "        # Handle all the other exceptions\n",
            "        print(f\"An unexpected error occurred: {e}\")\n",
            "\n",
            "    # Define an empty list to store the employee names\n",
            "    number_of_employees_to_warn = 0\n",
            "    employee_names = []\n",
            "\n",
            "    # Iterate over the child elements of the root element\n",
            "    for child in root:\n",
            "        if child.tag == \"total\":\n",
            "            number_of_employees_to_warn = int(child.text)\n",
            "        # If the child element is an employee element, extract the name and append it to the list\n",
            "        if child.tag.startswith(\"employee\"):\n",
            "            employee_names.append(child.text)\n",
            "\n",
            "    # Print the list of employee names\n",
            "    # print(number_of_employees_to_warn, employee_names)\n",
            "\n",
            "    return employee_names\n",
            "def internal_retriever_agent(text, filter=\"HR\"):\n",
            "    \"\"\"\n",
            "    Retrieve internal information related to the given text.\n",
            "\n",
            "    Args:\n",
            "        text (str): The text to search for.\n",
            "        filter (str, optional): The filter to apply to the search results. Defaults to 'HR'.\n",
            "\n",
            "    Returns:\n",
            "        list: A list of dictionaries containing the search results.\n",
            "    \"\"\"\n",
            "    vectorizer = get_vectorizer(\"mistral\")\n",
            "    query_vector = vectorizer.vectorize(text)\n",
            "\n",
            "    init_milvus_connection()\n",
            "\n",
            "    collection_name = \"mistral_collection\"\n",
            "    collection = Collection(name=collection_name)\n",
            "\n",
            "    n_neighbors = 20\n",
            "    results = collection.search(\n",
            "        [query_vector],\n",
            "        \"vector\",\n",
            "        param={\"metric_type\": \"L2\", \"params\": {}},\n",
            "        limit=n_neighbors,\n",
            "        expr=\"source == '\" + filter + \"'\",\n",
            "    )\n",
            "\n",
            "    final_indices = []\n",
            "    for result in results[0]:\n",
            "        if result.id not in final_indices and len(final_indices) + 1 <= n_neighbors:\n",
            "            final_indices.append([result.id, result.distance])\n",
            "            prev_index = result.id - 1\n",
            "            if (\n",
            "                prev_index >= 0\n",
            "                and prev_index not in final_indices\n",
            "                and len(final_indices) + 1 <= n_neighbors\n",
            "                and filter != \"HR\"\n",
            "            ):\n",
            "                final_indices.append([prev_index, result.distance])\n",
            "            next_index = result.id + 1\n",
            "            if (\n",
            "                next_index not in final_indices\n",
            "                and len(final_indices) + 1 <= n_neighbors\n",
            "                and filter != \"HR\"\n",
            "            ):\n",
            "                final_indices.append([next_index, result.distance])\n",
            "\n",
            "    results = final_indices\n",
            "\n",
            "    answer_chunks = []\n",
            "    unique_chunks = []\n",
            "    answer_chunks2 = []\n",
            "    for hit in results:\n",
            "        answer_chunk = find_chunks(hit[0])\n",
            "        if answer_chunk[\"document\"] in unique_chunks and filter == \"HR\":\n",
            "            continue\n",
            "        unique_chunks.append(answer_chunk[\"document\"])\n",
            "        answer_chunks.append(answer_chunk[\"text\"])\n",
            "        answer_chunks2.append(answer_chunk)\n",
            "        # print(find_chunks(hit[0]))\n",
            "        # print(find_chunks(hit[0])['fullpath'])\n",
            "\n",
            "    return answer_chunks2\n",
            "\n",
            "news_article1 = \"Data/External/News Articles/ New tax law in France aims to encourage and support the growth of startups and small businesses copy.docx\"\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    analyst_agent(news_article1, \"news article\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.6"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
